{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('winequality-red.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.quality\n",
    "x = df.drop(columns=['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set(style=\"ticks\")\n",
    "# sns.pairplot(df, hue=\"quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler()\n",
    "# x = sc.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# pca = PCA(n_components=11)\n",
    "# pca.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_test = x[-400:]\n",
    "y_test = y[-400:]\n",
    "\n",
    "x_train = x[:1199]\n",
    "y_train = y[:1199]\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=1/4, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1199, 11)\n",
      "(1199,)\n",
      "(400, 11)\n",
      "(400,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape) \n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE = 194\n",
      "Accuracy = 251\n",
      "Accuracy percent = 62.74999999999999%\n",
      "Accuracy: 0.81 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "# not tune\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0, warm_start=True)\n",
    "clf.fit(x_train, y_train)\n",
    "y_predict = clf.predict(x_test)\n",
    "tester.evaluate(y_predict, (y_test))\n",
    "# tester.cross_val(clf, df, y)\n",
    "tester.cross_val_accuracy(clf, df, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE = 309\n",
      "Accuracy = 202\n",
      "Accuracy percent = 50.5%\n",
      "Accuracy: 0.81 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "regr.fit(x_train, y_train)\n",
    "y_predict = regr.predict(x_test)\n",
    "y_predict = [int(i) for i in y_predict]\n",
    "tester.evaluate(y_predict, (y_test))\n",
    "# tester.cross_val(clf, df, y)\n",
    "tester.cross_val_accuracy(clf, df, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE = 313\n",
      "Accuracy = 189\n",
      "Accuracy percent = 47.25%\n",
      "Accuracy: 0.72 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(x_train, y_train)  \n",
    "y_predict = clf.predict(x_test)\n",
    "y_predict = [int(i) for i in y_predict]\n",
    "tester.evaluate(y_predict, (y_test))\n",
    "# tester.cross_val(clf, df, y)\n",
    "tester.cross_val_accuracy(clf, df, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE = 319\n",
      "Accuracy = 191\n",
      "Accuracy percent = 47.75%\n",
      "Accuracy: 0.67 (+/- 0.13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVR()\n",
    "clf.fit(x_train, y_train)  \n",
    "y_predict = clf.predict(x_test)\n",
    "y_predict = [int(i) for i in y_predict]\n",
    "tester.evaluate(y_predict, (y_test))\n",
    "# tester.cross_val(clf, df, y)\n",
    "tester.cross_val_accuracy(clf, df, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE = 1449\n",
      "Accuracy = 104\n",
      "Accuracy percent = 26.0%\n",
      "Accuracy: 0.28 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "import numpy as np\n",
    "clf = NearestCentroid()\n",
    "clf.fit(x_train, y_train)  \n",
    "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
    "y_predict=clf.predict(x_test)\n",
    "y_predict = [int(i) for i in y_predict]\n",
    "tester.evaluate(y_predict, (y_test))\n",
    "# tester.cross_val(clf, df, y)\n",
    "tester.cross_val_accuracy(clf, df, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE = 787\n",
      "Accuracy = 75\n",
      "Accuracy percent = 18.75%\n",
      "Accuracy: 0.46 (+/- 0.28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bundi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\bundi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\bundi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\bundi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\bundi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\bundi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\bundi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\bundi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\bundi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\bundi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\bundi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "clf.fit(x_train, y_train) \n",
    "y_predict=clf.predict(x_test)\n",
    "tester.evaluate(y_predict, (y_test))\n",
    "# tester.cross_val(clf, df, y)\n",
    "tester.cross_val_accuracy(clf, df, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import linear_model\n",
    "# reg = linear_model.BayesianRidge()\n",
    "# y_predict=reg.fit(x_train, y_train)\n",
    "# print(type(x_train), type(x_test))\n",
    "# tester.evaluate(list(y_predict), list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE = 388\n",
      "Accuracy = 175\n",
      "Accuracy percent = 43.75%\n",
      "Accuracy: 1.00 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "y_predict = []\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(x_train, y_train)  \n",
    "y_predict=clf.predict(x_test)\n",
    "tester.evaluate(list(y_predict), list(y_test))\n",
    "# tester.cross_val(clf, df, y)\n",
    "tester.cross_val_accuracy(clf, df, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE = 352\n",
      "Accuracy = 188\n",
      "Accuracy percent = 47.0%\n",
      "Accuracy: 1.00 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "# y_predict = []\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "clf.fit(x_train, y_train)\n",
    "y_predict=clf.predict(x_test)\n",
    "y_predict = [int(i) for i in y_predict]\n",
    "tester.evaluate(list(y_predict), list(y_test))\n",
    "# tester.cross_val(clf, df, y)\n",
    "tester.cross_val_accuracy(clf, df, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot([1,2,3], [1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE = 204\n",
      "Accuracy = 249\n",
      "Accuracy percent = 62.25000000000001%\n",
      "Accuracy: 1.00 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "# Tune\n",
    "# 56.25\n",
    "from sklearn import svm\n",
    "\n",
    "# ac_percent = []\n",
    "# for x in range(1,12):\n",
    "#     print(x)\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(x_train, y_train)  \n",
    "y_predict = clf.predict(x_test)\n",
    "y_predict = [int(i) for i in y_predict]\n",
    "tester.evaluate(y_predict, (y_test))\n",
    "tester.cross_val_accuracy(clf, df, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE = 208\n",
      "Accuracy = 228\n",
      "Accuracy percent = 56.99999999999999%\n",
      "[208, 228, 0.57]\n",
      "Accuracy: 1.00 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(x_train, y_train)  \n",
    "y_predict = clf.predict(x_test)\n",
    "y_predict = [int(i) for i in y_predict]\n",
    "print(tester.evaluate(y_predict, (y_test)))\n",
    "# tester.cross_val(clf, df, y)\n",
    "tester.cross_val_accuracy(clf, df, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_predict\n",
    "# predicted = cross_val_predict(clf, x, y, cv=10)\n",
    "# metrics.accuracy_score(y, predicted) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE = 204\n",
      "Accuracy = 249\n",
      "Accuracy percent = 62.25000000000001%\n",
      "[204, 249, 0.6225]\n",
      "Accuracy: 1.00 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(x_train, y_train)\n",
    "print(tester.evaluate(y_predict, (y_test)))\n",
    "tester.cross_val_accuracy(regr, df, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
